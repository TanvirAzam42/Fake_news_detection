# -*- coding: utf-8 -*-
"""fakenewsREal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u8QNYqdpdAAKDhsg9EeHfR1XIdEzs63m
"""

pip install beautifulsoup4 requests pandas scikit-learn

import requests
from bs4 import BeautifulSoup
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
import re

# Function to scrape news article text from a given URL
def scrape_article_text(url):
    try:
        response = requests.get(url)
        soup = BeautifulSoup(response.text, 'html.parser')
        # Extract text from paragraphs
        paragraphs = soup.find_all('p')
        text = ' '.join([p.get_text() for p in paragraphs])
        return text
    except Exception as e:
        print("Error scraping article:", e)
        return None

# Function to preprocess text
def preprocess_text(text):
    # Convert to lowercase
    text = text.lower()
    # Remove non-alphanumeric characters and extra whitespaces
    text = re.sub(r'[^a-zA-Z0-9\s]', '', text)
    text = re.sub(r'\s+', ' ', text)
    return text

# Load pre-trained fake news detection model
# For demonstration purposes, we'll use a simple model with TF-IDF and Naive Bayes
model = Pipeline([
    ('tfidf', TfidfVectorizer()),
    ('clf', MultinomialNB())
])

# Sample training data
training_data = [
    {'text': 'This is a real news article', 'label': 'real'},
    {'text': 'This is a fake news article', 'label': 'fake'}
]
X_train = [sample['text'] for sample in training_data]
y_train = [sample['label'] for sample in training_data]

# Fit the TF-IDF vectorizer with training data
model['tfidf'].fit(X_train)

# Train the model
model.fit(X_train, y_train)

# Example URLs to check
urls = [
    'https://www.indiatoday.in/education-today/news/story/meet-aditya-srivastava-upsc-2023-topper-and-aspiring-ips-officer-2527895-2024-04-16'
]

# Scrape articles and perform fake news detection
results = []
for url in urls:
    article_text = scrape_article_text(url)
    if article_text:
        preprocessed_text = preprocess_text(article_text)
        prediction = model.predict([preprocessed_text])[0]
        results.append({'url': url, 'prediction': prediction})

# Display results
for result in results:
    print(f"URL: {result['url']}")
    print(f"Prediction: {'Fake' if result['prediction'] == 'fake' else 'Real'}")
    print()